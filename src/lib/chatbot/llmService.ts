/**
 * ü§ñ LLM Service - Int√©gration DeepSeek / OpenAI GPT
 * Service robuste pour am√©liorer le chatbot avec une LLM
 */

import { ENV_CONFIG } from '@/config/env';

export interface LLMResponse {
  response: string;
  confidence: number;
  reasoning?: string;
}

type LLMProvider = 'deepseek' | 'openai';

export class LLMService {
  private apiKey: string;
  private enabled: boolean;
  private provider: LLMProvider;
  private baseUrl: string;
  private model: string;
  private maxRetries = 3;
  private retryDelay = 1000; // 1 second

  constructor() {
    // Priorit√©: DeepSeek > OpenAI
    if (ENV_CONFIG.DEEPSEEK_ENABLED && ENV_CONFIG.DEEPSEEK_API_KEY) {
      this.provider = 'deepseek';
      this.apiKey = ENV_CONFIG.DEEPSEEK_API_KEY;
      this.baseUrl = 'https://api.deepseek.com/v1';
      this.model = ENV_CONFIG.DEEPSEEK_MODEL || 'deepseek-chat';
      this.enabled = true;
      console.log('‚úÖ DeepSeek LLM enabled');
      console.log('üîë API Key configured:', this.apiKey.substring(0, 15) + '...');
      console.log('üì¶ Model:', this.model);
    } else if (ENV_CONFIG.OPENAI_ENABLED && ENV_CONFIG.OPENAI_API_KEY) {
      this.provider = 'openai';
      this.apiKey = ENV_CONFIG.OPENAI_API_KEY;
      this.baseUrl = 'https://api.openai.com/v1';
      this.model = 'gpt-3.5-turbo';
      this.enabled = true;
      console.log('‚úÖ OpenAI LLM enabled');
      console.log('üîë API Key configured:', this.apiKey.substring(0, 15) + '...');
    } else {
      this.enabled = false;
      this.provider = 'openai'; // Default fallback
      this.apiKey = '';
      this.baseUrl = '';
      this.model = '';
      console.log('‚ùå LLM Service disabled - No API key configured');
      console.log('üîç Debug - DEEPSEEK_ENABLED:', ENV_CONFIG.DEEPSEEK_ENABLED, '| OPENAI_ENABLED:', ENV_CONFIG.OPENAI_ENABLED);
    }
  }

  /**
   * G√©n√©re une r√©ponse intelligente avec DeepSeek / OpenAI GPT (avec retry logic)
   */
  async generateResponse(
    userMessage: string,
    context: {
      intent?: string;
      entities?: any[];
      conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>;
      platformContext?: any;
    }
  ): Promise<LLMResponse | null> {
    if (!this.enabled) {
      console.log('‚ö†Ô∏è LLM Service disabled, skipping');
      return null;
    }

    // Retry logic pour plus de robustesse
    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      try {
        console.log(`üöÄ Calling ${this.provider.toUpperCase()} API (attempt ${attempt}/${this.maxRetries}):`, userMessage.substring(0, 50) + '...');
        
        // Construire le syst√®me prompt avec contexte
        const systemPrompt = this.buildSystemPrompt(context);

        // Construire les messages
        const messages = this.buildMessages(systemPrompt, userMessage, context.conversationHistory);

        // Pr√©parer le body de la requ√™te
        const requestBody = {
          model: this.model,
          messages,
          temperature: 0.7,
          max_tokens: 800,
          stream: false
        };

        // Log de debug (sans la cl√© API compl√®te)
        if (attempt === 1) {
          console.log('üîç Request details:', {
            url: `${this.baseUrl}/chat/completions`,
            model: this.model,
            messagesCount: messages.length,
            apiKeyPrefix: this.apiKey.substring(0, 10) + '...'
          });
        }

        // Appel API avec timeout
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 30000); // 30s timeout

        try {
          const response = await fetch(`${this.baseUrl}/chat/completions`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${this.apiKey}`
            },
            body: JSON.stringify(requestBody),
            signal: controller.signal
          });

          clearTimeout(timeoutId);

          if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            const errorMessage = errorData?.error?.message || errorData?.message || response.statusText;
            
            // Log detailed error for debugging
            console.error(`‚ùå ${this.provider.toUpperCase()} API Error (${response.status}):`, {
              message: errorMessage,
              type: errorData?.error?.type,
              code: errorData?.error?.code,
              fullError: errorData
            });
            
            // Special handling for rate limits - retry with backoff
            if (response.status === 429) {
              if (attempt < this.maxRetries) {
                const backoffDelay = this.retryDelay * Math.pow(2, attempt - 1);
                console.warn(`‚ö†Ô∏è Rate limit reached, retrying in ${backoffDelay}ms...`);
                await this.delay(backoffDelay);
                continue;
              }
              console.warn('‚ö†Ô∏è Rate limit reached after retries, falling back to NLP');
              return null;
            }
            
            // Special handling for 400 errors (Bad Request) - don't retry, likely invalid request format
            if (response.status === 400) {
              console.error(`‚ùå Bad Request (400) - Likely invalid API key or request format: ${errorMessage}`);
              // Don't retry 400 errors, they won't succeed
              return null;
            }
            
            // Retry on server errors (5xx)
            if (response.status >= 500 && attempt < this.maxRetries) {
              console.warn(`‚ö†Ô∏è Server error ${response.status}, retrying...`);
              await this.delay(this.retryDelay * attempt);
              continue;
            }
            
            throw new Error(`${this.provider} API error: ${response.status} - ${errorMessage}`);
          }

          const data = await response.json();
          const aiResponse = data.choices[0]?.message?.content || '';

          if (!aiResponse || aiResponse.trim().length === 0) {
            throw new Error('Empty response from API');
          }

          console.log(`‚úÖ ${this.provider.toUpperCase()} response received:`, aiResponse.substring(0, 50) + '...');
          return {
            response: aiResponse.trim(),
            confidence: 0.85, // LLM responses generally have high confidence
            reasoning: `Generated by ${this.provider.toUpperCase()} ${this.model}`
          };
        } catch (fetchError: any) {
          clearTimeout(timeoutId);
          
          // Handle abort (timeout)
          if (fetchError.name === 'AbortError') {
            if (attempt < this.maxRetries) {
              console.warn(`‚ö†Ô∏è Request timeout, retrying...`);
              await this.delay(this.retryDelay * attempt);
              continue;
            }
            throw new Error('Request timeout after retries');
          }
          
          throw fetchError;
        }
      } catch (error: any) {
        console.error(`‚ùå LLM Service error (attempt ${attempt}/${this.maxRetries}):`, error);
        
        // Last attempt failed
        if (attempt === this.maxRetries) {
          console.error('‚ùå All retry attempts failed, falling back to NLP');
          return null; // Fallback to NLP engine
        }
        
        // Wait before retry
        await this.delay(this.retryDelay * attempt);
      }
    }

    return null;
  }

  /**
   * Helper pour delay
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Construire le prompt syst√®me avec contexte StudyMarket (am√©lior√©)
   */
  private buildSystemPrompt(context: any): string {
    return `Tu es l'assistant IA intelligent de StudyMarket, une plateforme de marketplace d√©di√©e aux √©tudiants v√©rifi√©s.

üéì CONTEXTE PLATEFORME:
- Plateforme d'√©change entre √©tudiants v√©rifi√©s uniquement
- Cat√©gories: livres, √©lectronique, v√™tements, mobilier, sports, logement, services, jobs
- Types de transactions: vente, don, troc, √©change
- Fonctionnalit√©s principales: annonces, messages s√©curis√©s, favoris, profil, commandes, paiements Stripe
- V√©rification: tous les utilisateurs sont v√©rifi√©s avec leur adresse email universitaire

ü§ñ TON R√îLE:
- R√©pondre de mani√®re amicale, professionnelle et concise
- Guider les utilisateurs vers les bonnes fonctionnalit√©s de la plateforme
- Proposer des suggestions pertinentes bas√©es sur le contexte
- Comprendre les intentions m√™me si mal formul√©es
- Adapter ton langage au niveau de l'utilisateur
- Si tu ne sais pas quelque chose, propose de contacter le support (support@studymarket.fr)

üìã R√àGLES IMPORTANTES:
- Reste concis (2-4 lignes maximum par r√©ponse)
- Utilise des emojis avec parcimonie (1-2 max par message)
- Sois toujours positif et encourageant
- Si l'utilisateur pose une question vague, pose une question de clarification
- Ne donne JAMAIS de conseils financiers, l√©gaux ou m√©dicaux
- Ne promets jamais quelque chose que tu ne peux pas garantir
- Si l'utilisateur semble frustr√©, sois empathique et propose une solution

üéØ INTENTIONS COMMUNES:
- Recherche d'articles: guide vers /listings avec filtres
- Cr√©ation d'annonce: guide vers /create (workflow √©tape par √©tape)
- Messages: guide vers /messages
- Profil: guide vers /profile
- Commandes: guide vers /orders
- Aide g√©n√©rale: guide vers /help ou /how-it-works

${context.intent ? `\nüéØ Intent d√©tect√©: ${context.intent}` : ''}
${context.entities && context.entities.length > 0 ? `\nüì¶ Entit√©s d√©tect√©es: ${context.entities.map((e: any) => `${e.type}: ${e.value}`).join(', ')}` : ''}
${context.platformContext?.currentPage ? `\nüìç Page actuelle: ${context.platformContext.currentPage}` : ''}

${context.platformContext?.workflowType ? `\nüîÑ WORKFLOW ACTIF - CR√âATION D'ANNONCE DYNAMIQUE:
- Type: ${context.platformContext.workflowType}
- Type de transaction d√©tect√©: ${context.platformContext.collectedData?.transactionType || 'sell (vente)'}
- √âtape actuelle: ${context.platformContext.workflowStep || 1}/5
- Donn√©es d√©j√† collect√©es: ${JSON.stringify(context.platformContext.collectedData || {})}
- Informations manquantes: ${context.platformContext.missingInfo?.join(', ') || 'aucune'}

üìã WORKFLOW DYNAMIQUE SELON LE TYPE D'ANNONCE:

**TYPE: VENTE (sell)** - Champs requis:
1. Nom de l'article (productName) - ${context.platformContext.collectedData?.productName || context.platformContext.collectedData?.title ? '‚úÖ Collect√©' : '‚ùå Manquant'}
2. Cat√©gorie (category) - ${context.platformContext.collectedData?.category ? '‚úÖ Collect√©' : '‚ùå Manquant'}
3. Prix (price) - ${context.platformContext.collectedData?.price ? '‚úÖ Collect√©' : '‚ùå Manquant'}
4. √âtat (condition) - ${context.platformContext.collectedData?.condition ? '‚úÖ Collect√©' : '‚ùå Manquant'}
5. Modes de paiement (paymentMethods) - ${context.platformContext.collectedData?.paymentMethods ? '‚úÖ Collect√©' : '‚ùå Manquant'}

**TYPE: DON (gift)** - Champs requis:
1. Nom de l'article (productName) - ${context.platformContext.collectedData?.productName || context.platformContext.collectedData?.title ? '‚úÖ Collect√©' : '‚ùå Manquant'}
2. Cat√©gorie (category) - ${context.platformContext.collectedData?.category ? '‚úÖ Collect√©' : '‚ùå Manquant'}
3. Raison du don (donationReason) - ${context.platformContext.collectedData?.donationReason ? '‚úÖ Collect√©' : '‚ùå Manquant'}

**TYPE: √âCHANGE (swap)** - Champs requis:
1. Nom de l'article (productName) - ${context.platformContext.collectedData?.productName || context.platformContext.collectedData?.title ? '‚úÖ Collect√©' : '‚ùå Manquant'}
2. Cat√©gorie (category) - ${context.platformContext.collectedData?.category ? '‚úÖ Collect√©' : '‚ùå Manquant'}
3. Objets recherch√©s (desiredItems) - ${context.platformContext.collectedData?.desiredItems ? '‚úÖ Collect√©' : '‚ùå Manquant'}
4. Valeur estim√©e (estimatedValue) - ${context.platformContext.collectedData?.estimatedValue ? '‚úÖ Collect√©' : '‚ùå Manquant'}

**TYPE: SERVICE** - Champs requis:
1. Nom du service (productName) - ${context.platformContext.collectedData?.productName || context.platformContext.collectedData?.title ? '‚úÖ Collect√©' : '‚ùå Manquant'}
2. Cat√©gorie (category) - ${context.platformContext.collectedData?.category ? '‚úÖ Collect√©' : '‚ùå Manquant'}
3. Tarif horaire (hourlyRate) - ${context.platformContext.collectedData?.hourlyRate ? '‚úÖ Collect√©' : '‚ùå Manquant'}
4. Dur√©e (duration) - ${context.platformContext.collectedData?.duration ? '‚úÖ Collect√©' : '‚ùå Manquant'}
5. Comp√©tences (skills) - ${context.platformContext.collectedData?.skills ? '‚úÖ Collect√©' : '‚ùå Manquant'}

üéØ TON R√îLE DANS LE WORKFLOW - SOIS INTELLIGENT ET DYNAMIQUE:
- Si l'utilisateur r√©pond √† une question du workflow, EXTRACTE l'information de sa r√©ponse IMM√âDIATEMENT
- Guide-le vers l'√©tape suivante de mani√®re NATURELLE et FLUIDE (pas de r√©p√©tition)
- Sois POSITIF et MOTIVANT √† chaque √©tape (ex: "Super !", "Parfait !", "Excellent !")
- Si l'utilisateur donne plusieurs infos en une fois, reconnais-les TOUTES et f√©licite-le
- Ne r√©p√®te JAMAIS les questions d√©j√† pos√©es si l'info est d√©j√† collect√©e
- Montre la PROGRESSION clairement (ex: "√âtape 2/5", "On avance bien !")
- Donne des EXEMPLES CONCRETS √† chaque √©tape pour aider l'utilisateur
- Si l'utilisateur clique sur une suggestion, traite-la comme une r√©ponse valide
- SOIS PROACTIF : Si tu d√©tectes qu'une √©tape est compl√©t√©e, passe IMM√âDIATEMENT √† la suivante
- NE REDIS PAS ce qui a d√©j√† √©t√© dit - progresse naturellement
- Si l'utilisateur dit "Un livre de maths", passe DIRECTEMENT √† l'√©tape 2/5 (cat√©gorie)
- Si l'utilisateur dit "Livres & Cours", passe DIRECTEMENT √† l'√©tape 3/5 (prix)

üí° EXEMPLES D'EXTRACTION:
- Utilisateur dit "un livre de maths" ‚Üí productName = "livre de maths"
- Utilisateur dit "50 euros" ou "50‚Ç¨" ‚Üí price = 50
- Utilisateur dit "√©lectronique" ou "üìö Livres & Cours" ‚Üí category = correspondante
- Utilisateur dit "comme neuf" ou "üåü Comme neuf" ‚Üí condition = "comme neuf"
- Utilisateur dit "gratuit" ou "üíù Gratuit" ‚Üí price = 0

üí¨ STYLE DE COMMUNICATION - SOIS DYNAMIQUE:
- Utilise des emojis pour rendre le message plus vivant (üéØ, ‚úÖ, üí°, üì¶, etc.)
- Sois CONCIS mais COMPLET - pas de r√©p√©tition inutile
- Montre un R√âCAPITULATIF BRIEF des infos collect√©es (juste ce qui est nouveau)
- Encourage l'utilisateur √† continuer
- PROGRESSE NATURELLEMENT - ne reste pas bloqu√© sur une √©tape
- Si l'utilisateur a d√©j√† donn√© une info, ne la redemande PAS

üöÄ EXEMPLE DE PROGRESSION INTELLIGENTE:
- Utilisateur: "Un livre de maths niveau L1"
- Toi: "Parfait ! 'Un livre de maths niveau L1' üì¶\n\n**√âtape 2/5** : Dans quelle cat√©gorie ? üè∑Ô∏è\n\nüí° Je sugg√®re 'üìö Livres & Cours' - √ßa te convient ?"
- (PAS: "Super ! Je vais t'aider..." - c'est d√©j√† fait, progresse !)

IMPORTANT: Sois PROACTIF, INTELLIGENT, DYNAMIQUE. Ne r√©p√®te pas, progresse naturellement. Si une √©tape est compl√©t√©e, passe IMM√âDIATEMENT √† la suivante.` : ''}

R√©ponds maintenant de mani√®re naturelle et utile. Si l'utilisateur est dans un workflow, guide-le vers l'√©tape suivante et extrait les informations de sa r√©ponse.`;
  }

  /**
   * Construire les messages pour l'API
   */
  private buildMessages(
    systemPrompt: string,
    userMessage: string,
    history?: Array<{ role: 'user' | 'assistant'; content: string }>
  ): any[] {
    const messages: any[] = [
      { role: 'system', content: systemPrompt }
    ];

    // Ajouter l'historique r√©cent (max 5 derniers messages)
    if (history && history.length > 0) {
      const recentHistory = history.slice(-5);
      messages.push(...recentHistory);
    }

    // Ajouter le message actuel
    messages.push({ role: 'user', content: userMessage });

    return messages;
  }

  /**
   * D√©cider si l'on doit utiliser la LLM
   */
  shouldUseLLM(nlpConfidence: number, intent: string, workflowContext?: any, userMessage?: string): boolean {
    if (!this.enabled) return false;
    
    // TOUJOURS utiliser LLM si dans un workflow (pour meilleure compr√©hension contextuelle)
    if (workflowContext?.activeWorkflow) {
      return true;
    }
    
    // Utiliser LLM si:
    // - Confiance NLP faible (< 0.5)
    // - Intent UNKNOWN
    // - Message court ou ambigu (probablement mal compris)
    // - Contient des caract√®res sp√©ciaux ou formules (ex: "1+1")
    const isShortOrAmbiguous = userMessage && (
      userMessage.length < 10 || 
      /[+\-*/=<>]/.test(userMessage) || // Contient des op√©rateurs math√©matiques
      /^\d+[\s+\-*/]\d+/.test(userMessage) // Formule simple comme "1+1"
    );
    
    if (isShortOrAmbiguous) {
      console.log('ü§ñ Using LLM for short/ambiguous message:', userMessage);
      return true;
    }
    
    // Demandes complexes n√©cessitant du raisonnement
    return nlpConfidence < 0.5 || intent === 'unknown';
  }
}

// ==================== SINGLETON EXPORT ====================

export const llmService = new LLMService();
